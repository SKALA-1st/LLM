{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2xf6YbpltIe"
   },
   "source": [
    "임성열 Ph.D. 2025. 02.05, SKALA 수업 학습목적으로만 활용 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 75688,
     "status": "ok",
     "timestamp": 1733991041610,
     "user": {
      "displayName": "Sung Ryel Lim",
      "userId": "17832580391396757133"
     },
     "user_tz": -540
    },
    "id": "HJc141DwTkEr",
    "outputId": "16614bfa-3f27-4b30-ffd4-87f7ea56e7f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting crewai==0.28.8\n",
      "  Downloading crewai-0.28.8-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting crewai_tools==0.1.6\n",
      "  Downloading crewai_tools-0.1.6-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain_community==0.0.29\n",
      "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex<2024.0.0,>=2023.12.25\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 KB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting instructor<0.6.0,>=0.5.2\n",
      "  Downloading instructor-0.5.2-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.13.3 in /config/.local/lib/python3.10/site-packages (from crewai==0.28.8) (1.61.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.30.0-py3-none-any.whl (17 kB)\n",
      "Collecting embedchain<0.2.0,>=0.1.98\n",
      "  Downloading embedchain-0.1.126-py3-none-any.whl (211 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting appdirs<2.0.0,>=1.4.4\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai==0.28.8) (2.10.6)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.22.0\n",
      "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from crewai==0.28.8) (8.1.8)\n",
      "Collecting langchain<0.2.0,>=0.1.10\n",
      "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv==1.0.0\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.22.0\n",
      "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lancedb<0.6.0,>=0.5.4\n",
      "  Downloading lancedb-0.5.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytest<9.0.0,>=8.0.0\n",
      "  Downloading pytest-8.3.4-py3-none-any.whl (343 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.1/343.1 KB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyright<2.0.0,>=1.1.350\n",
      "  Downloading pyright-1.1.393-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from crewai_tools==0.1.6) (2.32.3)\n",
      "Collecting chromadb<0.5.0,>=0.4.22\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 KB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /config/.local/lib/python3.10/site-packages (from crewai_tools==0.1.6) (4.13.1)\n",
      "Collecting selenium<5.0.0,>=4.18.1\n",
      "  Downloading selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytube<16.0.0,>=15.0.0\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /config/.local/lib/python3.10/site-packages (from langchain_community==0.0.29) (0.6.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (3.11.11)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /config/.local/lib/python3.10/site-packages (from langchain_community==0.0.29) (2.0.37)\n",
      "Collecting langsmith<0.2.0,>=0.1.0\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33\n",
      "  Downloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 KB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /config/.local/lib/python3.10/site-packages (from langchain_community==0.0.29) (1.26.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (0.2.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (25.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (2.4.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.18.3)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (6.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /config/.local/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (4.12.2)\n",
      "Collecting build>=1.0.3\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Collecting pulsar-client>=3.1.0\n",
      "  Downloading pulsar_client-3.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting overrides>=7.3.1\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Collecting pypika>=0.48.9\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bcrypt>=4.0.1\n",
      "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 KB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mmh3>=4.0.1\n",
      "  Downloading mmh3-5.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kubernetes>=28.1.0\n",
      "  Downloading kubernetes-32.0.0-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fastapi>=0.95.2 in /config/.local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.115.6)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /config/.local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.34.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.10.15)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (4.67.1)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
      "Collecting typer>=0.9.0\n",
      "  Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting posthog>=2.4.0\n",
      "  Downloading posthog-3.11.0-py2.py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting chroma-hnswlib==0.7.3\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.21.0)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.58.0\n",
      "  Downloading grpcio-1.70.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime>=1.14.1\n",
      "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /config/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /config/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29) (0.9.0)\n",
      "Collecting schema<0.8.0,>=0.7.5\n",
      "  Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
      "Collecting langchain-cohere<0.4.0,>=0.3.0\n",
      "  Downloading langchain_cohere-0.3.5-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting embedchain<0.2.0,>=0.1.98\n",
      "  Downloading embedchain-0.1.125-py3-none-any.whl (211 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 KB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading embedchain-0.1.124-py3-none-any.whl (211 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 KB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading embedchain-0.1.123-py3-none-any.whl (210 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.9/210.9 KB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading embedchain-0.1.122-py3-none-any.whl (210 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.9/210.9 KB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-openai<0.2.0,>=0.1.7\n",
      "  Downloading langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting embedchain<0.2.0,>=0.1.98\n",
      "  Downloading embedchain-0.1.121-py3-none-any.whl (210 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.9/210.9 KB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mem0ai<0.0.21,>=0.0.20\n",
      "  Downloading mem0ai-0.0.20-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting embedchain<0.2.0,>=0.1.98\n",
      "  Downloading embedchain-0.1.120-py3-none-any.whl (210 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.9/210.9 KB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mem0ai<0.0.10,>=0.0.9\n",
      "  Downloading mem0ai-0.0.9-py3-none-any.whl (29 kB)\n",
      "Collecting embedchain<0.2.0,>=0.1.98\n",
      "  Downloading embedchain-0.1.119-py3-none-any.whl (209 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.3/209.3 KB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading embedchain-0.1.118-py3-none-any.whl (209 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.3/209.3 KB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading embedchain-0.1.117-py3-none-any.whl (209 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading embedchain-0.1.116-py3-none-any.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 KB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading embedchain-0.1.115-py3-none-any.whl (206 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.8/206.8 KB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading embedchain-0.1.114-py3-none-any.whl (203 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.5/203.5 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-aiplatform<2.0.0,>=1.26.1\n",
      "  Downloading google_cloud_aiplatform-1.79.0-py2.py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting alembic<2.0.0,>=1.13.1\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 KB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pypdf<5.0.0,>=4.0.1\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 KB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gptcache<0.2.0,>=0.1.43\n",
      "  Downloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tiktoken<0.8.0,>=0.7.0\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pysbd<0.4.0,>=0.3.4\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-cohere<0.2.0,>=0.1.4\n",
      "  Downloading langchain_cohere-0.1.9-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (13.9.4)\n",
      "Collecting embedchain<0.2.0,>=0.1.98\n",
      "  Downloading embedchain-0.1.113-py3-none-any.whl (202 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 KB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting clarifai<11.0.0,>=10.0.1\n",
      "  Downloading clarifai-10.11.1-py3-none-any.whl (167 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: embedchain 0.1.126 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.126 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting PyGithub<2.0.0,>=1.59.1\n",
      "  Downloading PyGithub-1.59.1-py3-none-any.whl (342 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 KB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: gitpython<4.0.0,>=3.1.38 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.1.44)\n",
      "Collecting youtube-transcript-api<0.7.0,>=0.6.1\n",
      "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 KB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yt_dlp<2024.0.0,>=2023.11.14\n",
      "  Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docstring-parser<0.16,>=0.15\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Collecting typer>=0.9.0\n",
      "  Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting retry>=0.9.2\n",
      "  Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
      "Collecting ratelimiter~=1.0\n",
      "  Downloading ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
      "Collecting deprecation\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting semver>=3.0\n",
      "  Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (5.5.1)\n",
      "Collecting pylance==0.9.18\n",
      "  Downloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=12 in /usr/local/lib/python3.10/dist-packages (from pylance==0.9.18->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (19.0.0)\n",
      "Collecting langchain<0.2.0,>=0.1.10\n",
      "  Downloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 KB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai==0.28.8) (1.33)\n",
      "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 KB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain-0.1.15-py3-none-any.whl (814 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m814.5/814.5 KB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain-0.1.14-py3-none-any.whl (812 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 KB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 KB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1\n",
      "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Collecting packaging<24.0,>=23.2\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (1.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.28.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (4.8.0)\n",
      "Collecting deprecated>=1.2.6\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
      "Collecting googleapis-common-protos~=1.52\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.7/221.7 KB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-proto==1.30.0\n",
      "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.30.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (5.29.3)\n",
      "Collecting opentelemetry-semantic-conventions==0.51b0\n",
      "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (2.27.2)\n",
      "Collecting nodeenv>=1.6.0\n",
      "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (1.2.2)\n",
      "Collecting pluggy<2,>=1.5\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting tomli>=1\n",
      "  Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.10)\n",
      "Collecting websocket-client~=1.8\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting trio~=0.17\n",
      "  Downloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 KB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /config/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.0.29) (3.1.1)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyproject_hooks\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Collecting inquirerpy==0.3.4\n",
      "  Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting clarifai-grpc>=10.11.2\n",
      "  Downloading clarifai_grpc-11.0.7-py3-none-any.whl (262 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.1/262.1 KB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tabulate>=0.9.0\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting tritonclient>=2.34.0\n",
      "  Downloading tritonclient-2.54.0-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting clarifai-protocol>=0.0.14\n",
      "  Downloading clarifai_protocol-0.0.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (362 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.5/362.5 KB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting schema<0.8.0,>=0.7.5\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: Pillow>=9.5.0 in /usr/local/lib/python3.10/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (11.1.0)\n",
      "Collecting fsspec==2024.6.1\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 KB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting click<9.0.0,>=8.1.7\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contextlib2>=0.5.5\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /config/.local/lib/python3.10/site-packages (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.50)\n",
      "Collecting pfzy<0.4.0,>=0.3.1\n",
      "  Downloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: starlette<0.42.0,>=0.40.0 in /config/.local/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.41.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4.0.0,>=3.1.38->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (4.0.12)\n",
      "Collecting shapely<3.0.0dev\n",
      "  Downloading shapely-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0\n",
      "  Downloading google_cloud_bigquery-3.29.0-py2.py3-none-any.whl (244 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.6/244.6 KB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
      "  Downloading google_cloud_resource_manager-1.14.0-py2.py3-none-any.whl (384 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.1/384.1 KB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting proto-plus<2.0.0dev,>=1.22.3\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 KB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3.0.0dev,>=2.14.1\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 KB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-storage<3.0.0dev,>=1.32.0\n",
      "  Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.14.0)\n",
      "Collecting zipp>=3.20\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.10->crewai==0.28.8) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.9.0.post0)\n",
      "Collecting durationpy>=0.7\n",
      "  Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Collecting requests-oauthlib\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting oauthlib>=3.2.2\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.17.0)\n",
      "Collecting langchain-cohere<0.2.0,>=0.1.4\n",
      "  Downloading langchain_cohere-0.1.8-py3-none-any.whl (31 kB)\n",
      "  Downloading langchain_cohere-0.1.7-py3-none-any.whl (31 kB)\n",
      "  Downloading langchain_cohere-0.1.5-py3-none-any.whl (30 kB)\n",
      "Collecting cohere<6.0,>=5.5\n",
      "  Downloading cohere-5.13.11-py3-none-any.whl (252 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.5/252.5 KB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-openai<0.2.0,>=0.1.7\n",
      "  Downloading langchain_openai-0.1.24-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.6/51.6 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.23-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.22-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.20-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.19-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.17-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.16-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.15-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.14-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.13-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.12-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.11-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.10-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.9-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\n",
      "  Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
      "Collecting flatbuffers\n",
      "  Downloading flatbuffers-25.1.24-py2.py3-none-any.whl (30 kB)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.51b0\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
      "Collecting opentelemetry-instrumentation==0.51b0\n",
      "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
      "Collecting opentelemetry-util-http==0.51b0\n",
      "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
      "Collecting asgiref~=3.0\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Collecting backoff>=1.10.0\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting monotonic>=1.5\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting pyjwt[crypto]>=2.4.0\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Collecting pynacl>=1.4.0\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 KB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting py<2.0.0,>=1.4.26\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator>=3.4.2 in /config/.local/lib/python3.10/site-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (5.1.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.28.1)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /config/.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29) (1.0.0)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-14.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.3/169.3 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13\n",
      "  Downloading watchfiles-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting httptools>=0.6.3\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 KB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting defusedxml<0.8.0,>=0.7.1\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting brotli\n",
      "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mutagen\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 KB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pycryptodomex\n",
      "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting clarifai-protocol>=0.0.14\n",
      "  Downloading clarifai_protocol-0.0.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.7/361.7 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting types-requests<3.0.0,>=2.0.0\n",
      "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /config/.local/lib/python3.10/site-packages (from cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.4.0)\n",
      "Collecting fastavro<2.0.0,>=1.9.4\n",
      "  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.38->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (5.0.2)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl (14 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 KB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-core<3.0.0dev,>=2.4.1\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=2.0.0\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpc-google-iam-v1<1.0.0dev,>=0.12.4\n",
      "  Downloading grpc_google_iam_v1-0.14.0-py2.py3-none-any.whl (27 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.2)\n",
      "Collecting cryptography>=3.4.0\n",
      "  Downloading cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cffi>=1.4.1\n",
      "  Downloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m446.2/446.2 KB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-rapidjson>=0.9.1\n",
      "  Downloading python_rapidjson-1.20-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.2)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pycparser\n",
      "  Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wcwidth in /config/.local/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.2.13)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53738 sha256=30120246c6ecb27fdadb332e90c504c6fbcbeb869e9e706ae2f0aabac624e1e8\n",
      "  Stored in directory: /config/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: sortedcontainers, ratelimiter, pypika, mpmath, monotonic, flatbuffers, durationpy, brotli, appdirs, zipp, wsproto, wrapt, websockets, websocket-client, uvloop, types-requests, tomli, tenacity, tabulate, sympy, shapely, semver, regex, pytube, python-rapidjson, python-dotenv, pysocks, pysbd, pyproject_hooks, pypdf, pylance, pyjwt, pycryptodomex, pycparser, pyasn1, py, pulsar-client, proto-plus, pluggy, pfzy, packaging, overrides, outcome, opentelemetry-util-http, opentelemetry-proto, oauthlib, nodeenv, mutagen, mmh3, Mako, iniconfig, importlib-resources, humanfriendly, httptools, grpcio, googleapis-common-protos, google-crc32c, fsspec, fastavro, docstring-parser, defusedxml, contextlib2, click, chroma-hnswlib, bcrypt, backoff, asgiref, yt_dlp, youtube-transcript-api, watchfiles, typer, tritonclient, trio, tiktoken, schema, rsa, retry, requests-oauthlib, pytest, pyright, pyasn1-modules, posthog, opentelemetry-exporter-otlp-proto-common, inquirerpy, importlib-metadata, grpcio-status, gptcache, google-resumable-media, deprecation, deprecated, coloredlogs, clarifai-grpc, cffi, build, alembic, trio-websocket, pynacl, opentelemetry-api, onnxruntime, langsmith, lancedb, grpc-google-iam-v1, google-auth, cryptography, selenium, opentelemetry-semantic-conventions, langchain-core, kubernetes, instructor, google-api-core, cohere, PyGithub, opentelemetry-sdk, opentelemetry-instrumentation, langchain-text-splitters, langchain-openai, langchain_community, langchain-cohere, google-cloud-core, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, langchain, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, opentelemetry-instrumentation-fastapi, google-cloud-aiplatform, chromadb, clarifai-protocol, clarifai, embedchain, crewai_tools, crewai\n",
      "  Attempting uninstall: pypdf\n",
      "    Found existing installation: pypdf 5.2.0\n",
      "    Uninstalling pypdf-5.2.0:\n",
      "      Successfully uninstalled pypdf-5.2.0\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.8.0\n",
      "    Uninstalling tiktoken-0.8.0:\n",
      "      Successfully uninstalled tiktoken-0.8.0\n",
      "  Attempting uninstall: langchain_community\n",
      "    Found existing installation: langchain-community 0.3.16\n",
      "    Uninstalling langchain-community-0.3.16:\n",
      "      Successfully uninstalled langchain-community-0.3.16\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-groq 0.2.4 requires langchain-core<0.4.0,>=0.3.33, but you have langchain-core 0.1.53 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.9 PyGithub-1.59.1 alembic-1.14.1 appdirs-1.4.4 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 brotli-1.1.0 build-1.2.2.post1 cffi-1.17.1 chroma-hnswlib-0.7.3 chromadb-0.4.24 clarifai-10.11.1 clarifai-grpc-11.0.7 clarifai-protocol-0.0.14 click-8.1.7 cohere-5.13.11 coloredlogs-15.0.1 contextlib2-21.6.0 crewai-0.28.8 crewai_tools-0.1.6 cryptography-44.0.0 defusedxml-0.7.1 deprecated-1.2.18 deprecation-2.1.0 docstring-parser-0.15 durationpy-0.9 embedchain-0.1.113 fastavro-1.10.0 flatbuffers-25.1.24 fsspec-2024.6.1 google-api-core-2.24.1 google-auth-2.38.0 google-cloud-aiplatform-1.79.0 google-cloud-bigquery-3.29.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.14.0 google-cloud-storage-2.19.0 google-crc32c-1.6.0 google-resumable-media-2.7.2 googleapis-common-protos-1.66.0 gptcache-0.1.44 grpc-google-iam-v1-0.14.0 grpcio-1.70.0 grpcio-status-1.70.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.5.0 importlib-resources-6.5.2 iniconfig-2.0.0 inquirerpy-0.3.4 instructor-0.5.2 kubernetes-32.0.0 lancedb-0.5.7 langchain-0.1.13 langchain-cohere-0.1.5 langchain-core-0.1.53 langchain-openai-0.1.7 langchain-text-splitters-0.0.2 langchain_community-0.0.29 langsmith-0.1.147 mmh3-5.1.0 monotonic-1.6 mpmath-1.3.0 mutagen-1.47.0 nodeenv-1.9.1 oauthlib-3.2.2 onnxruntime-1.20.1 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-exporter-otlp-proto-http-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 outcome-1.3.0.post0 overrides-7.7.0 packaging-23.2 pfzy-0.3.4 pluggy-1.5.0 posthog-3.11.0 proto-plus-1.26.0 pulsar-client-3.6.0 py-1.11.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycparser-2.22 pycryptodomex-3.21.0 pyjwt-2.10.1 pylance-0.9.18 pynacl-1.5.0 pypdf-4.3.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyright-1.1.393 pysbd-0.3.4 pysocks-1.7.1 pytest-8.3.4 python-dotenv-1.0.0 python-rapidjson-1.20 pytube-15.0.0 ratelimiter-1.2.0.post0 regex-2023.12.25 requests-oauthlib-2.0.0 retry-0.9.2 rsa-4.9 schema-0.7.5 selenium-4.28.1 semver-3.0.4 shapely-2.0.7 sortedcontainers-2.4.0 sympy-1.13.3 tabulate-0.9.0 tenacity-8.5.0 tiktoken-0.7.0 tomli-2.2.1 trio-0.28.0 trio-websocket-0.11.1 tritonclient-2.54.0 typer-0.9.4 types-requests-2.32.0.20241016 uvloop-0.21.0 watchfiles-1.0.4 websocket-client-1.8.0 websockets-14.2 wrapt-1.17.2 wsproto-1.2.0 youtube-transcript-api-0.6.3 yt_dlp-2023.12.30 zipp-3.21.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai==1.55.3\n",
      "  Downloading openai-1.55.3-py3-none-any.whl (389 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting httpx==0.27.2\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (1.3.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (4.12.2)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (2025.1.31)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.55.3) (1.2.2)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.55.3) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.55.3) (0.7.0)\n",
      "Installing collected packages: httpx, openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.61.0\n",
      "    Uninstalling openai-1.61.0:\n",
      "      Successfully uninstalled openai-1.61.0\n",
      "Successfully installed httpx-0.27.2 openai-1.55.3\n"
     ]
    }
   ],
   "source": [
    "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29\n",
    "!pip install openai==1.55.3 httpx==0.27.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1733991054867,
     "user": {
      "displayName": "Sung Ryel Lim",
      "userId": "17832580391396757133"
     },
     "user_tz": -540
    },
    "height": 64,
    "id": "hc15bfrPTf2H"
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6405,
     "status": "ok",
     "timestamp": 1733991063581,
     "user": {
      "displayName": "Sung Ryel Lim",
      "userId": "17832580391396757133"
     },
     "user_tz": -540
    },
    "height": 30,
    "id": "GUpYG2AXTf2I"
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1733991065177,
     "user": {
      "displayName": "Sung Ryel Lim",
      "userId": "17832580391396757133"
     },
     "user_tz": -540
    },
    "height": 98,
    "id": "9w0UJ8WGTf2J"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-4o-mini'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2KsLYF0Tf2J"
   },
   "source": [
    "Agent(에이전트) 생성하기\n",
    "\n",
    "Agent를 정의하고, role(역할), goal(목표), backstory(배경 설명)를 제공합니다.\n",
    "\n",
    "LLM(대규모 언어 모델)은 롤플레잉을 할 때 더 나은 성능을 보이는 것으로 확인되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUz7YSJpTf2J"
   },
   "source": [
    "### Agent: 기획자(Planner)\n",
    "\n",
    "**참고**: _여러 문자열_ 사용의 이점:\n",
    "```Python\n",
    "varname = \"텍스트의 첫 번째 줄\"\n",
    "          \"텍스트의 두 번째 줄\"\n",
    "```\n",
    "\n",
    "_삼중 따옴표 독스트링_ 사용과 비교했을 때:\n",
    "```Python\n",
    "varname = \"\"\"텍스트의 첫 번째 줄\n",
    "             텍스트의 두 번째 줄\n",
    "          \"\"\"\n",
    "```\n",
    "여러 문자열을 사용하면 공백과 줄바꿈 문자가 추가되는 것을 피할 수 있어, LLM에 전달할 때 더 나은 형식을 유지할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1851,
     "status": "ok",
     "timestamp": 1733991077976,
     "user": {
      "displayName": "Sung Ryel Lim",
      "userId": "17832580391396757133"
     },
     "user_tz": -540
    },
    "height": 234,
    "id": "v8h_39g3Tf2K"
   },
   "outputs": [],
   "source": [
    "planner = Agent(\n",
    "    role=\"콘텐츠 기획자\",\n",
    "    goal=\"{topic}에 대한 흥미로운 콘텐츠 기획\",\n",
    "    backstory=\"당신은 {topic}에 대한 글을 \"\n",
    "              \"기획하는 일을 하고 있습니다. \",\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jM-zQC2JTf2K"
   },
   "source": [
    "### Agent: Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1733991082111,
     "user": {
      "displayName": "Sung Ryel Lim",
      "userId": "17832580391396757133"
     },
     "user_tz": -540
    },
    "height": 370,
    "id": "Q732-epnTf2K"
   },
   "outputs": [],
   "source": [
    "writer = Agent(\n",
    "    role=\"콘텐츠 작성자\",\n",
    "    goal=\"{topic}에 대한\"\n",
    "         \"의견을 포함한 글을 작성\",\n",
    "    backstory=\"당신은 {topic}에 대한\"\n",
    "              \"의견을 포함한 기사를 작성하고 있습니다. \",\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWUNpt29Tf2K"
   },
   "source": [
    "### Agent: Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1733991085196,
     "user": {
      "displayName": "Sung Ryel Lim",
      "userId": "17832580391396757133"
     },
     "user_tz": -540
    },
    "height": 268,
    "id": "9xnDvxIDTf2K"
   },
   "outputs": [],
   "source": [
    "editor = Agent(\n",
    "    role=\"편집자\",\n",
    "    goal=\"주어진 기사 글을 올바른 표준 국어 형식 및 조직의 글 서식에 맞게 편집\",\n",
    "    backstory=\"당신은 콘텐츠 작성자로부터 \"\n",
    "              \"기사 글을 받는 편집자입니다. \",\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMlksZgITf2K"
   },
   "source": [
    "## Task(작업) 생성하기\n",
    "\n",
    "- Task를 정의하고, `description`(설명), `expected_output`(예상 결과물), `agent`(수행 에이전트)를 제공합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBNTQ48rTf2K"
   },
   "source": [
    "### Task: Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1733991093924,
     "user": {
      "displayName": "Sung Ryel Lim",
      "userId": "17832580391396757133"
     },
     "user_tz": -540
    },
    "height": 268,
    "id": "7u5O6jLQTf2L"
   },
   "outputs": [],
   "source": [
    "plan = Task(\n",
    "    description=(\n",
    "        \"{topic}에 대한 최신 트렌드, 주요 인물, \"\n",
    "        \"그리고 주목할 만한 뉴스를 우선순위화하기.\\n\"\n",
    "    ),\n",
    "    expected_output=\"개요, 독자층 분석, \",\n",
    "    agent=planner,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpYfPWHpTf2L"
   },
   "source": [
    "### Task: Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1733991097643,
     "user": {
      "displayName": "Sung Ryel Lim",
      "userId": "17832580391396757133"
     },
     "user_tz": -540
    },
    "height": 319,
    "id": "Dch6sY44Tf2L"
   },
   "outputs": [],
   "source": [
    "write = Task(\n",
    "    description=(\n",
    "        \"1. 콘텐츠 기획을 활용하여 {topic}에 대한 \"\n",
    "            \"매력적인 블로그 글 작성하기.\\n\"\n",
    "    ),\n",
    "    expected_output=\"각 섹션이 2~3개의 문단으로 구성된 글, \",\n",
    "    agent=writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gtkz1jgoTf2L"
   },
   "source": [
    "### Task: Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1733991104026,
     "user": {
      "displayName": "Sung Ryel Lim",
      "userId": "17832580391396757133"
     },
     "user_tz": -540
    },
    "height": 166,
    "id": "ZyQRdPvgTf2L"
   },
   "outputs": [],
   "source": [
    "edit = Task(\n",
    "    description=(\"주어진 블로그 글의 문법 오류를 검토하고 \"\n",
    "                 \"브랜드의 톤앤매너와 일치하는지 확인하기.\"),\n",
    "    expected_output=\"각 섹션이 2~3개의 문단으로 구성된, \"\n",
    "                    \"지침에 맞추어진 준비가 완료된 마크다운 형식의 글\",\n",
    "    agent=editor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7Uw_J9iTf2L"
   },
   "source": [
    "## Crew(팀) 생성하기\n",
    "\n",
    "- Agent들로 구성된 팀을 생성합니다\n",
    "- 해당 Agent들이 수행할 작업들을 전달합니다.\n",
    "    - **참고**: *이 간단한 예시에서는* 작업들이 순차적으로 수행됩니다(즉, 서로 의존적임). 따라서 목록에서의 작업 _순서_가 _중요_합니다.\n",
    "- `verbose=2`를 설정하면 실행의 모든 로그를 확인할 수 있습니다.\n",
    "\n",
    "\n",
    "이 설정에서:\n",
    "1. `planner`가 먼저 콘텐츠를 기획합니다\n",
    "2. `writer`가 기획된 내용을 바탕으로 글을 작성합니다\n",
    "3. `editor`가 최종적으로 작성된 글을 검토하고 편집합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1733991109926,
     "user": {
      "displayName": "Sung Ryel Lim",
      "userId": "17832580391396757133"
     },
     "user_tz": -540
    },
    "height": 98,
    "id": "4qFEjv2STf2L"
   },
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[planner, writer, editor],\n",
    "    tasks=[plan, write, edit],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VV0SCjyqTf2M"
   },
   "source": [
    "## Running the Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQow07uUHL3c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39529,
     "status": "ok",
     "timestamp": 1733991160104,
     "user": {
      "displayName": "Sung Ryel Lim",
      "userId": "17832580391396757133"
     },
     "user_tz": -540
    },
    "height": 30,
    "id": "bsfxOgXDTf2M",
    "outputId": "c03268ac-b756-44fa-d00a-699917e43131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: 콘텐츠 기획자\u001b[00m\n",
      "\u001b[1m\u001b[95m [INFO]: == Starting Task: 생성형 AI를 이용한 제약회사 경쟁력 제고 방안에 대한 최신 트렌드, 주요 인물, 그리고 주목할 만한 뉴스를 우선순위화하기.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now can give a great answer  \n",
      "Final Answer: \n",
      "\n",
      "**개요**  \n",
      "생성형 AI는 최근 제약업계에서 혁신과 경쟁력 제고의 중요한 도구로 부각되고 있습니다. 이 기술은 신약 개발, 임상 시험 최적화, 환자 맞춤형 치료 전략 수립, 그리고 마케팅 및 판매 전략 개선 등 여러 분야에서 활용되고 있습니다. 특히, 데이터 분석과 예측 모델링을 통해 제약회사들이 보다 빠르고 정확한 의사 결정을 내릴 수 있도록 도와줍니다. 본 글에서는 생성형 AI의 최신 트렌드, 주요 인물, 그리고 주목할 만한 뉴스들을 우선순위화하여 제약회사 경쟁력 제고 방안을 제시하고자 합니다.\n",
      "\n",
      "**독자층 분석**  \n",
      "이 콘텐츠는 제약회사 관계자, 연구개발(R&D) 부서 직원, 데이터 과학자, 마케팅 및 세일즈 팀, 그리고 제약 산업에 관심이 있는 일반 독자들을 대상으로 합니다. 특히, 제약업계의 최신 기술 트렌드에 관심이 있는 전문가와 의사결정자는 이 글에서 유용한 인사이트를 얻을 수 있을 것입니다.\n",
      "\n",
      "**최신 트렌드**  \n",
      "1. **신약 발견 및 개발 가속화**  \n",
      "   - 생성형 AI는 화합물의 구조를 설계하고, 예상되는 생물학적 활성을 예측하여 신약 발견 과정을 혁신하고 있습니다. 예를 들어, DeepMind의 AlphaFold는 단백질 구조를 예측하는 데 있어 획기적인 발전을 이뤘습니다.\n",
      "\n",
      "2. **임상 시험 효율성 향상**  \n",
      "   - 환자 선정, 시험 설계, 데이터 분석 과정에서 AI를 활용하여 임상 시험의 성공률을 높이고 기간을 단축할 수 있습니다. IBM Watson Health는 이러한 솔루션을 제공하여 임상 시험의 품질을 높이고 있습니다.\n",
      "\n",
      "3. **환자 맞춤형 치료**  \n",
      "   - 생성형 AI는 유전자 데이터와 환자의 병력 정보를 분석하여 개인 맞춤형 치료법을 개발하는 데 기여하고 있습니다. 이를 통해 환자들의 치료 반응을 극대화하고 부작용을 최소화할 수 있습니다.\n",
      "\n",
      "4. **마케팅 및 판매 전략 개선**  \n",
      "   - AI를 통한 시장 분석 및 소비자 행동 예측은 제약회사가 더 효과적으로 제품을 출시하고, 마케팅 전략을 조정할 수 있도록 지원합니다. 예를 들어, Salesforce의 AI 기반 플랫폼은 고객의 요구를 예측하여 맞춤형 마케팅 전략을 수립하는 데 도움을 주고 있습니다.\n",
      "\n",
      "**주요 인물**  \n",
      "- **Andrew Ng**: AI의 선두주자로, 제약 산업에 AI 기술을 도입하는 데 기여하고 있습니다.\n",
      "- **Fei-Fei Li**: AI 윤리 및 데이터 사용에 대한 논의를 이끌며, 제약 분야에서의 책임 있는 AI 사용을 강조하고 있습니다.\n",
      "- **Demis Hassabis**: DeepMind의 CEO로, 생명과학 분야에서 AI 기술의 활용을 선도하고 있습니다.\n",
      "\n",
      "**주목할 만한 뉴스**  \n",
      "1. **Moderna와 AI 협업**  \n",
      "   - Moderna는 AI 기술을 활용하여 mRNA 기반 백신의 개발 속도를 높이고 있으며, 이러한 협업을 통해 혁신적인 치료법을 지속적으로 선보이고 있습니다.\n",
      "\n",
      "2. **AI 기반 신약 개발 스타트업의 증가**  \n",
      "   - 최근 다수의 스타트업들이 AI를 기반으로 한 신약 개발에 뛰어들고 있으며, 이는 제약업계의 경쟁 구조를 변화시키고 있습니다. \n",
      "\n",
      "3. **FDA의 AI 규제 강화**  \n",
      "   - 미국 FDA는 AI 및 머신러닝을 활용한 의료기기와 치료법에 대한 규제를 강화하고 있으며, 이는 안전하고 효과적인 AI 활용을 위한 중요한 발판이 될 것입니다.\n",
      "\n",
      "**결론**  \n",
      "생성형 AI는 제약회사의 경쟁력을 높이는 데 있어 중요한 역할을 하며, 이를 통해 혁신적인 신약 개발과 환자 맞춤형 치료, 효율적인 임상 시험 운영 및 효과적인 마케팅 전략 수립이 가능해집니다. 제약업계 관계자들은 이러한 최신 트렌드와 인사이트를 바탕으로 경쟁력을 제고할 수 있는 전략을 모색해야 할 것입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [DEBUG]: == [콘텐츠 기획자] Task output: **개요**  \n",
      "생성형 AI는 최근 제약업계에서 혁신과 경쟁력 제고의 중요한 도구로 부각되고 있습니다. 이 기술은 신약 개발, 임상 시험 최적화, 환자 맞춤형 치료 전략 수립, 그리고 마케팅 및 판매 전략 개선 등 여러 분야에서 활용되고 있습니다. 특히, 데이터 분석과 예측 모델링을 통해 제약회사들이 보다 빠르고 정확한 의사 결정을 내릴 수 있도록 도와줍니다. 본 글에서는 생성형 AI의 최신 트렌드, 주요 인물, 그리고 주목할 만한 뉴스들을 우선순위화하여 제약회사 경쟁력 제고 방안을 제시하고자 합니다.\n",
      "\n",
      "**독자층 분석**  \n",
      "이 콘텐츠는 제약회사 관계자, 연구개발(R&D) 부서 직원, 데이터 과학자, 마케팅 및 세일즈 팀, 그리고 제약 산업에 관심이 있는 일반 독자들을 대상으로 합니다. 특히, 제약업계의 최신 기술 트렌드에 관심이 있는 전문가와 의사결정자는 이 글에서 유용한 인사이트를 얻을 수 있을 것입니다.\n",
      "\n",
      "**최신 트렌드**  \n",
      "1. **신약 발견 및 개발 가속화**  \n",
      "   - 생성형 AI는 화합물의 구조를 설계하고, 예상되는 생물학적 활성을 예측하여 신약 발견 과정을 혁신하고 있습니다. 예를 들어, DeepMind의 AlphaFold는 단백질 구조를 예측하는 데 있어 획기적인 발전을 이뤘습니다.\n",
      "\n",
      "2. **임상 시험 효율성 향상**  \n",
      "   - 환자 선정, 시험 설계, 데이터 분석 과정에서 AI를 활용하여 임상 시험의 성공률을 높이고 기간을 단축할 수 있습니다. IBM Watson Health는 이러한 솔루션을 제공하여 임상 시험의 품질을 높이고 있습니다.\n",
      "\n",
      "3. **환자 맞춤형 치료**  \n",
      "   - 생성형 AI는 유전자 데이터와 환자의 병력 정보를 분석하여 개인 맞춤형 치료법을 개발하는 데 기여하고 있습니다. 이를 통해 환자들의 치료 반응을 극대화하고 부작용을 최소화할 수 있습니다.\n",
      "\n",
      "4. **마케팅 및 판매 전략 개선**  \n",
      "   - AI를 통한 시장 분석 및 소비자 행동 예측은 제약회사가 더 효과적으로 제품을 출시하고, 마케팅 전략을 조정할 수 있도록 지원합니다. 예를 들어, Salesforce의 AI 기반 플랫폼은 고객의 요구를 예측하여 맞춤형 마케팅 전략을 수립하는 데 도움을 주고 있습니다.\n",
      "\n",
      "**주요 인물**  \n",
      "- **Andrew Ng**: AI의 선두주자로, 제약 산업에 AI 기술을 도입하는 데 기여하고 있습니다.\n",
      "- **Fei-Fei Li**: AI 윤리 및 데이터 사용에 대한 논의를 이끌며, 제약 분야에서의 책임 있는 AI 사용을 강조하고 있습니다.\n",
      "- **Demis Hassabis**: DeepMind의 CEO로, 생명과학 분야에서 AI 기술의 활용을 선도하고 있습니다.\n",
      "\n",
      "**주목할 만한 뉴스**  \n",
      "1. **Moderna와 AI 협업**  \n",
      "   - Moderna는 AI 기술을 활용하여 mRNA 기반 백신의 개발 속도를 높이고 있으며, 이러한 협업을 통해 혁신적인 치료법을 지속적으로 선보이고 있습니다.\n",
      "\n",
      "2. **AI 기반 신약 개발 스타트업의 증가**  \n",
      "   - 최근 다수의 스타트업들이 AI를 기반으로 한 신약 개발에 뛰어들고 있으며, 이는 제약업계의 경쟁 구조를 변화시키고 있습니다. \n",
      "\n",
      "3. **FDA의 AI 규제 강화**  \n",
      "   - 미국 FDA는 AI 및 머신러닝을 활용한 의료기기와 치료법에 대한 규제를 강화하고 있으며, 이는 안전하고 효과적인 AI 활용을 위한 중요한 발판이 될 것입니다.\n",
      "\n",
      "**결론**  \n",
      "생성형 AI는 제약회사의 경쟁력을 높이는 데 있어 중요한 역할을 하며, 이를 통해 혁신적인 신약 개발과 환자 맞춤형 치료, 효율적인 임상 시험 운영 및 효과적인 마케팅 전략 수립이 가능해집니다. 제약업계 관계자들은 이러한 최신 트렌드와 인사이트를 바탕으로 경쟁력을 제고할 수 있는 전략을 모색해야 할 것입니다.\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: 콘텐츠 작성자\u001b[00m\n",
      "\u001b[1m\u001b[95m [INFO]: == Starting Task: 1. 콘텐츠 기획을 활용하여 생성형 AI를 이용한 제약회사 경쟁력 제고 방안에 대한 매력적인 블로그 글 작성하기.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now can give a great answer  \n",
      "Final Answer: \n",
      "\n",
      "**생성형 AI를 이용한 제약회사 경쟁력 제고 방안**\n",
      "\n",
      "**개요**  \n",
      "최근 제약업계에서 생성형 AI는 혁신과 경쟁력 제고의 중추적인 도구로 자리 잡고 있습니다. 이 기술은 신약 개발, 임상 시험 최적화, 환자 맞춤형 치료 전략 수립, 마케팅 및 판매 전략 개선 등 다양한 분야에서 활용되고 있으며, 데이터 분석과 예측 모델링을 통해 제약회사들이 보다 효율적이고 정교한 의사 결정을 내릴 수 있도록 지원하고 있습니다. 본 글에서는 생성형 AI의 최신 트렌드, 주요 인물, 그리고 주목할 만한 뉴스들을 중심으로 제약회사 경쟁력 제고 방안을 제시하고자 합니다.\n",
      "\n",
      "**최신 트렌드**  \n",
      "첫번째로, 생성형 AI는 신약 발견 및 개발을 가속화하는 데 큰 기여를 하고 있습니다. 예를 들어, DeepMind의 AlphaFold는 단백질 구조 예측에 있어 혁신적인 발전을 이루어, 화합물의 구조 설계와 생물학적 활성을 예측하는 데 도움을 줍니다. 이는 제약회사들이 새로운 치료제를 보다 빠르게 개발할 수 있도록 지원하며, 시장에서의 경쟁 우위를 강화하는 데 기여합니다.\n",
      "\n",
      "두번째로, 임상 시험의 효율성을 향상시키는 데 있어 생성형 AI는 필수적인 역할을 하고 있습니다. 환자 선정, 시험 설계, 데이터 분석 과정에서 AI를 활용하여 임상 시험의 성공률을 높이고 기간을 단축할 수 있습니다. IBM Watson Health와 같은 기업들은 이러한 솔루션을 제공하여 임상 시험의 품질을 개선하고, 결과적으로 제약 회사의 시간과 비용을 절감하는 데 도움을 주고 있습니다.\n",
      "\n",
      "세번째로, 환자 맞춤형 치료의 발전도 주목할 만합니다. 생성형 AI는 유전자 데이터 및 환자의 병력 정보를 분석하여 개인 맞춤형 치료법을 개발하는 데 기여하고 있습니다. 이를 통해 환자들의 치료 반응을 극대화하고 부작용을 최소화할 수 있는 가능성이 열리고 있으며, 이는 환자 만족도를 높이고 치료 성과를 개선하는 데 중요한 요소로 작용하고 있습니다.\n",
      "\n",
      "**주요 인물**  \n",
      "AI 분야의 선두주자인 Andrew Ng는 제약 산업에 AI 기술을 도입하는 데 기여하며, 이 기술의 발전 가능성을 널리 알리고 있습니다. 또한, Fei-Fei Li는 AI 윤리와 데이터 사용에 대한 논의를 이끌며 제약 분야에서의 책임 있는 AI 사용을 강조하고 있습니다. Demis Hassabis, DeepMind의 CEO는 생명과학 분야에서 AI 기술의 선도적인 활용을 통해 제약 산업의 혁신을 이끌고 있습니다.\n",
      "\n",
      "**주목할 만한 뉴스**  \n",
      "Moderna는 AI 기술을 활용하여 mRNA 기반 백신의 개발 속도를 높이고 있으며, 이러한 협업은 혁신적인 치료법을 지속적으로 선보이는 데 기여하고 있습니다. 또한, AI 기반 신약 개발 스타트업들이 증가함에 따라 제약업계의 경쟁 구조가 변화하고 있습니다. 이러한 변화는 새로운 아이디어와 접근 방식을 통해 제약 산업의 발전을 이끌어 낼 것입니다. 마지막으로, 미국 FDA는 AI 및 머신러닝을 활용한 의료기기와 치료법에 대한 규제를 강화하고 있으며, 이는 안전하고 효과적인 AI 활용을 위한 중요한 기초를 마련하고 있습니다.\n",
      "\n",
      "**결론**  \n",
      "생성형 AI는 제약회사의 경쟁력을 높이는 데 있어 중요한 역할을 합니다. 이를 통해 혁신적인 신약 개발, 환자 맞춤형 치료, 효율적인 임상 시험 운영 및 효과적인 마케팅 전략 수립이 가능해집니다. 제약업계 관계자들은 이러한 최신 트렌드와 인사이트를 바탕으로 경쟁력을 제고할 수 있는 전략을 모색해야 하며, 미래의 제약 산업에서 성공하기 위해서는 생성형 AI의 도입과 활용이 필수적입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [DEBUG]: == [콘텐츠 작성자] Task output: **생성형 AI를 이용한 제약회사 경쟁력 제고 방안**\n",
      "\n",
      "**개요**  \n",
      "최근 제약업계에서 생성형 AI는 혁신과 경쟁력 제고의 중추적인 도구로 자리 잡고 있습니다. 이 기술은 신약 개발, 임상 시험 최적화, 환자 맞춤형 치료 전략 수립, 마케팅 및 판매 전략 개선 등 다양한 분야에서 활용되고 있으며, 데이터 분석과 예측 모델링을 통해 제약회사들이 보다 효율적이고 정교한 의사 결정을 내릴 수 있도록 지원하고 있습니다. 본 글에서는 생성형 AI의 최신 트렌드, 주요 인물, 그리고 주목할 만한 뉴스들을 중심으로 제약회사 경쟁력 제고 방안을 제시하고자 합니다.\n",
      "\n",
      "**최신 트렌드**  \n",
      "첫번째로, 생성형 AI는 신약 발견 및 개발을 가속화하는 데 큰 기여를 하고 있습니다. 예를 들어, DeepMind의 AlphaFold는 단백질 구조 예측에 있어 혁신적인 발전을 이루어, 화합물의 구조 설계와 생물학적 활성을 예측하는 데 도움을 줍니다. 이는 제약회사들이 새로운 치료제를 보다 빠르게 개발할 수 있도록 지원하며, 시장에서의 경쟁 우위를 강화하는 데 기여합니다.\n",
      "\n",
      "두번째로, 임상 시험의 효율성을 향상시키는 데 있어 생성형 AI는 필수적인 역할을 하고 있습니다. 환자 선정, 시험 설계, 데이터 분석 과정에서 AI를 활용하여 임상 시험의 성공률을 높이고 기간을 단축할 수 있습니다. IBM Watson Health와 같은 기업들은 이러한 솔루션을 제공하여 임상 시험의 품질을 개선하고, 결과적으로 제약 회사의 시간과 비용을 절감하는 데 도움을 주고 있습니다.\n",
      "\n",
      "세번째로, 환자 맞춤형 치료의 발전도 주목할 만합니다. 생성형 AI는 유전자 데이터 및 환자의 병력 정보를 분석하여 개인 맞춤형 치료법을 개발하는 데 기여하고 있습니다. 이를 통해 환자들의 치료 반응을 극대화하고 부작용을 최소화할 수 있는 가능성이 열리고 있으며, 이는 환자 만족도를 높이고 치료 성과를 개선하는 데 중요한 요소로 작용하고 있습니다.\n",
      "\n",
      "**주요 인물**  \n",
      "AI 분야의 선두주자인 Andrew Ng는 제약 산업에 AI 기술을 도입하는 데 기여하며, 이 기술의 발전 가능성을 널리 알리고 있습니다. 또한, Fei-Fei Li는 AI 윤리와 데이터 사용에 대한 논의를 이끌며 제약 분야에서의 책임 있는 AI 사용을 강조하고 있습니다. Demis Hassabis, DeepMind의 CEO는 생명과학 분야에서 AI 기술의 선도적인 활용을 통해 제약 산업의 혁신을 이끌고 있습니다.\n",
      "\n",
      "**주목할 만한 뉴스**  \n",
      "Moderna는 AI 기술을 활용하여 mRNA 기반 백신의 개발 속도를 높이고 있으며, 이러한 협업은 혁신적인 치료법을 지속적으로 선보이는 데 기여하고 있습니다. 또한, AI 기반 신약 개발 스타트업들이 증가함에 따라 제약업계의 경쟁 구조가 변화하고 있습니다. 이러한 변화는 새로운 아이디어와 접근 방식을 통해 제약 산업의 발전을 이끌어 낼 것입니다. 마지막으로, 미국 FDA는 AI 및 머신러닝을 활용한 의료기기와 치료법에 대한 규제를 강화하고 있으며, 이는 안전하고 효과적인 AI 활용을 위한 중요한 기초를 마련하고 있습니다.\n",
      "\n",
      "**결론**  \n",
      "생성형 AI는 제약회사의 경쟁력을 높이는 데 있어 중요한 역할을 합니다. 이를 통해 혁신적인 신약 개발, 환자 맞춤형 치료, 효율적인 임상 시험 운영 및 효과적인 마케팅 전략 수립이 가능해집니다. 제약업계 관계자들은 이러한 최신 트렌드와 인사이트를 바탕으로 경쟁력을 제고할 수 있는 전략을 모색해야 하며, 미래의 제약 산업에서 성공하기 위해서는 생성형 AI의 도입과 활용이 필수적입니다.\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: 편집자\u001b[00m\n",
      "\u001b[1m\u001b[95m [INFO]: == Starting Task: 주어진 블로그 글의 문법 오류를 검토하고 브랜드의 톤앤매너와 일치하는지 확인하기.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now can give a great answer  \n",
      "Final Answer: \n",
      "\n",
      "# 생성형 AI를 이용한 제약회사 경쟁력 제고 방안\n",
      "\n",
      "## 개요  \n",
      "최근 제약업계에서 생성형 AI는 혁신과 경쟁력 제고의 중추적인 도구로 자리 잡고 있습니다. 이 기술은 신약 개발, 임상 시험 최적화, 환자 맞춤형 치료 전략 수립, 마케팅 및 판매 전략 개선 등 다양한 분야에서 활용되고 있으며, 데이터 분석과 예측 모델링을 통해 제약회사들이 보다 효율적이고 정교한 의사 결정을 내릴 수 있도록 지원하고 있습니다. 본 글에서는 생성형 AI의 최신 트렌드, 주요 인물, 그리고 주목할 만한 뉴스들을 중심으로 제약회사 경쟁력 제고 방안을 제시하고자 합니다.\n",
      "\n",
      "## 최신 트렌드  \n",
      "첫 번째로, 생성형 AI는 신약 발견 및 개발을 가속화하는 데 큰 기여를 하고 있습니다. 예를 들어, DeepMind의 AlphaFold는 단백질 구조 예측에 있어 혁신적인 발전을 이루어, 화합물의 구조 설계와 생물학적 활성을 예측하는 데 도움을 줍니다. 이는 제약회사들이 새로운 치료제를 보다 빠르게 개발할 수 있도록 지원하며, 시장에서의 경쟁 우위를 강화하는 데 기여합니다.\n",
      "\n",
      "두 번째로, 임상 시험의 효율성을 향상시키는 데 있어 생성형 AI는 필수적인 역할을 하고 있습니다. 환자 선정, 시험 설계, 데이터 분석 과정에서 AI를 활용하여 임상 시험의 성공률을 높이고 기간을 단축할 수 있습니다. IBM Watson Health와 같은 기업들은 이러한 솔루션을 제공하여 임상 시험의 품질을 개선하고, 결과적으로 제약 회사의 시간과 비용을 절감하는 데 도움을 주고 있습니다.\n",
      "\n",
      "세 번째로, 환자 맞춤형 치료의 발전도 주목할 만합니다. 생성형 AI는 유전자 데이터 및 환자의 병력 정보를 분석하여 개인 맞춤형 치료법을 개발하는 데 기여하고 있습니다. 이를 통해 환자들의 치료 반응을 극대화하고 부작용을 최소화할 수 있는 가능성이 열리고 있으며, 이는 환자 만족도를 높이고 치료 성과를 개선하는 데 중요한 요소로 작용하고 있습니다.\n",
      "\n",
      "## 주요 인물  \n",
      "AI 분야의 선두주자인 Andrew Ng는 제약 산업에 AI 기술을 도입하는 데 기여하며, 이 기술의 발전 가능성을 널리 알리고 있습니다. 또한, Fei-Fei Li는 AI 윤리와 데이터 사용에 대한 논의를 이끌며 제약 분야에서의 책임 있는 AI 사용을 강조하고 있습니다. Demis Hassabis, DeepMind의 CEO는 생명과학 분야에서 AI 기술의 선도적인 활용을 통해 제약 산업의 혁신을 이끌고 있습니다.\n",
      "\n",
      "## 주목할 만한 뉴스  \n",
      "Moderna는 AI 기술을 활용하여 mRNA 기반 백신의 개발 속도를 높이고 있으며, 이러한 협업은 혁신적인 치료법을 지속적으로 선보이는 데 기여하고 있습니다. 또한, AI 기반 신약 개발 스타트업들이 증가함에 따라 제약업계의 경쟁 구조가 변화하고 있습니다. 이러한 변화는 새로운 아이디어와 접근 방식을 통해 제약 산업의 발전을 이끌어 낼 것입니다. 마지막으로, 미국 FDA는 AI 및 머신러닝을 활용한 의료기기와 치료법에 대한 규제를 강화하고 있으며, 이는 안전하고 효과적인 AI 활용을 위한 중요한 기초를 마련하고 있습니다.\n",
      "\n",
      "## 결론  \n",
      "생성형 AI는 제약회사의 경쟁력을 높이는 데 있어 중요한 역할을 합니다. 이를 통해 혁신적인 신약 개발, 환자 맞춤형 치료, 효율적인 임상 시험 운영 및 효과적인 마케팅 전략 수립이 가능해집니다. 제약업계 관계자들은 이러한 최신 트렌드와 인사이트를 바탕으로 경쟁력을 제고할 수 있는 전략을 모색해야 하며, 미래의 제약 산업에서 성공하기 위해서는 생성형 AI의 도입과 활용이 필수적입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [DEBUG]: == [편집자] Task output: # 생성형 AI를 이용한 제약회사 경쟁력 제고 방안\n",
      "\n",
      "## 개요  \n",
      "최근 제약업계에서 생성형 AI는 혁신과 경쟁력 제고의 중추적인 도구로 자리 잡고 있습니다. 이 기술은 신약 개발, 임상 시험 최적화, 환자 맞춤형 치료 전략 수립, 마케팅 및 판매 전략 개선 등 다양한 분야에서 활용되고 있으며, 데이터 분석과 예측 모델링을 통해 제약회사들이 보다 효율적이고 정교한 의사 결정을 내릴 수 있도록 지원하고 있습니다. 본 글에서는 생성형 AI의 최신 트렌드, 주요 인물, 그리고 주목할 만한 뉴스들을 중심으로 제약회사 경쟁력 제고 방안을 제시하고자 합니다.\n",
      "\n",
      "## 최신 트렌드  \n",
      "첫 번째로, 생성형 AI는 신약 발견 및 개발을 가속화하는 데 큰 기여를 하고 있습니다. 예를 들어, DeepMind의 AlphaFold는 단백질 구조 예측에 있어 혁신적인 발전을 이루어, 화합물의 구조 설계와 생물학적 활성을 예측하는 데 도움을 줍니다. 이는 제약회사들이 새로운 치료제를 보다 빠르게 개발할 수 있도록 지원하며, 시장에서의 경쟁 우위를 강화하는 데 기여합니다.\n",
      "\n",
      "두 번째로, 임상 시험의 효율성을 향상시키는 데 있어 생성형 AI는 필수적인 역할을 하고 있습니다. 환자 선정, 시험 설계, 데이터 분석 과정에서 AI를 활용하여 임상 시험의 성공률을 높이고 기간을 단축할 수 있습니다. IBM Watson Health와 같은 기업들은 이러한 솔루션을 제공하여 임상 시험의 품질을 개선하고, 결과적으로 제약 회사의 시간과 비용을 절감하는 데 도움을 주고 있습니다.\n",
      "\n",
      "세 번째로, 환자 맞춤형 치료의 발전도 주목할 만합니다. 생성형 AI는 유전자 데이터 및 환자의 병력 정보를 분석하여 개인 맞춤형 치료법을 개발하는 데 기여하고 있습니다. 이를 통해 환자들의 치료 반응을 극대화하고 부작용을 최소화할 수 있는 가능성이 열리고 있으며, 이는 환자 만족도를 높이고 치료 성과를 개선하는 데 중요한 요소로 작용하고 있습니다.\n",
      "\n",
      "## 주요 인물  \n",
      "AI 분야의 선두주자인 Andrew Ng는 제약 산업에 AI 기술을 도입하는 데 기여하며, 이 기술의 발전 가능성을 널리 알리고 있습니다. 또한, Fei-Fei Li는 AI 윤리와 데이터 사용에 대한 논의를 이끌며 제약 분야에서의 책임 있는 AI 사용을 강조하고 있습니다. Demis Hassabis, DeepMind의 CEO는 생명과학 분야에서 AI 기술의 선도적인 활용을 통해 제약 산업의 혁신을 이끌고 있습니다.\n",
      "\n",
      "## 주목할 만한 뉴스  \n",
      "Moderna는 AI 기술을 활용하여 mRNA 기반 백신의 개발 속도를 높이고 있으며, 이러한 협업은 혁신적인 치료법을 지속적으로 선보이는 데 기여하고 있습니다. 또한, AI 기반 신약 개발 스타트업들이 증가함에 따라 제약업계의 경쟁 구조가 변화하고 있습니다. 이러한 변화는 새로운 아이디어와 접근 방식을 통해 제약 산업의 발전을 이끌어 낼 것입니다. 마지막으로, 미국 FDA는 AI 및 머신러닝을 활용한 의료기기와 치료법에 대한 규제를 강화하고 있으며, 이는 안전하고 효과적인 AI 활용을 위한 중요한 기초를 마련하고 있습니다.\n",
      "\n",
      "## 결론  \n",
      "생성형 AI는 제약회사의 경쟁력을 높이는 데 있어 중요한 역할을 합니다. 이를 통해 혁신적인 신약 개발, 환자 맞춤형 치료, 효율적인 임상 시험 운영 및 효과적인 마케팅 전략 수립이 가능해집니다. 제약업계 관계자들은 이러한 최신 트렌드와 인사이트를 바탕으로 경쟁력을 제고할 수 있는 전략을 모색해야 하며, 미래의 제약 산업에서 성공하기 위해서는 생성형 AI의 도입과 활용이 필수적입니다.\n",
      "\n",
      "\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "result = crew.kickoff(inputs={\"topic\": \"생성형 AI를 이용한 제약회사 경쟁력 제고 방안\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iqjhGxGTf2M"
   },
   "source": [
    "- Display the results of your execution as markdown in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1733991170715,
     "user": {
      "displayName": "Sung Ryel Lim",
      "userId": "17832580391396757133"
     },
     "user_tz": -540
    },
    "height": 47,
    "id": "VEEgWLc9Tf2M",
    "outputId": "5d58ff68-b6a2-42ef-bff7-c9f108800a9a"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# 생성형 AI를 이용한 제약회사 경쟁력 제고 방안\n",
       "\n",
       "## 개요  \n",
       "최근 제약업계에서 생성형 AI는 혁신과 경쟁력 제고의 중추적인 도구로 자리 잡고 있습니다. 이 기술은 신약 개발, 임상 시험 최적화, 환자 맞춤형 치료 전략 수립, 마케팅 및 판매 전략 개선 등 다양한 분야에서 활용되고 있으며, 데이터 분석과 예측 모델링을 통해 제약회사들이 보다 효율적이고 정교한 의사 결정을 내릴 수 있도록 지원하고 있습니다. 본 글에서는 생성형 AI의 최신 트렌드, 주요 인물, 그리고 주목할 만한 뉴스들을 중심으로 제약회사 경쟁력 제고 방안을 제시하고자 합니다.\n",
       "\n",
       "## 최신 트렌드  \n",
       "첫 번째로, 생성형 AI는 신약 발견 및 개발을 가속화하는 데 큰 기여를 하고 있습니다. 예를 들어, DeepMind의 AlphaFold는 단백질 구조 예측에 있어 혁신적인 발전을 이루어, 화합물의 구조 설계와 생물학적 활성을 예측하는 데 도움을 줍니다. 이는 제약회사들이 새로운 치료제를 보다 빠르게 개발할 수 있도록 지원하며, 시장에서의 경쟁 우위를 강화하는 데 기여합니다.\n",
       "\n",
       "두 번째로, 임상 시험의 효율성을 향상시키는 데 있어 생성형 AI는 필수적인 역할을 하고 있습니다. 환자 선정, 시험 설계, 데이터 분석 과정에서 AI를 활용하여 임상 시험의 성공률을 높이고 기간을 단축할 수 있습니다. IBM Watson Health와 같은 기업들은 이러한 솔루션을 제공하여 임상 시험의 품질을 개선하고, 결과적으로 제약 회사의 시간과 비용을 절감하는 데 도움을 주고 있습니다.\n",
       "\n",
       "세 번째로, 환자 맞춤형 치료의 발전도 주목할 만합니다. 생성형 AI는 유전자 데이터 및 환자의 병력 정보를 분석하여 개인 맞춤형 치료법을 개발하는 데 기여하고 있습니다. 이를 통해 환자들의 치료 반응을 극대화하고 부작용을 최소화할 수 있는 가능성이 열리고 있으며, 이는 환자 만족도를 높이고 치료 성과를 개선하는 데 중요한 요소로 작용하고 있습니다.\n",
       "\n",
       "## 주요 인물  \n",
       "AI 분야의 선두주자인 Andrew Ng는 제약 산업에 AI 기술을 도입하는 데 기여하며, 이 기술의 발전 가능성을 널리 알리고 있습니다. 또한, Fei-Fei Li는 AI 윤리와 데이터 사용에 대한 논의를 이끌며 제약 분야에서의 책임 있는 AI 사용을 강조하고 있습니다. Demis Hassabis, DeepMind의 CEO는 생명과학 분야에서 AI 기술의 선도적인 활용을 통해 제약 산업의 혁신을 이끌고 있습니다.\n",
       "\n",
       "## 주목할 만한 뉴스  \n",
       "Moderna는 AI 기술을 활용하여 mRNA 기반 백신의 개발 속도를 높이고 있으며, 이러한 협업은 혁신적인 치료법을 지속적으로 선보이는 데 기여하고 있습니다. 또한, AI 기반 신약 개발 스타트업들이 증가함에 따라 제약업계의 경쟁 구조가 변화하고 있습니다. 이러한 변화는 새로운 아이디어와 접근 방식을 통해 제약 산업의 발전을 이끌어 낼 것입니다. 마지막으로, 미국 FDA는 AI 및 머신러닝을 활용한 의료기기와 치료법에 대한 규제를 강화하고 있으며, 이는 안전하고 효과적인 AI 활용을 위한 중요한 기초를 마련하고 있습니다.\n",
       "\n",
       "## 결론  \n",
       "생성형 AI는 제약회사의 경쟁력을 높이는 데 있어 중요한 역할을 합니다. 이를 통해 혁신적인 신약 개발, 환자 맞춤형 치료, 효율적인 임상 시험 운영 및 효과적인 마케팅 전략 수립이 가능해집니다. 제약업계 관계자들은 이러한 최신 트렌드와 인사이트를 바탕으로 경쟁력을 제고할 수 있는 전략을 모색해야 하며, 미래의 제약 산업에서 성공하기 위해서는 생성형 AI의 도입과 활용이 필수적입니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
